{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56458840-a827-438f-bd33-af0c6cfb899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install bs4\n",
    "%pip install requests_html\n",
    "%pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b378bf0f-527e-4404-b05b-8e5f2b1e29ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from requests_html import HTMLSession\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6fa2999-59cb-472a-82e9-e825eda16e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#truth values\n",
    "true = \"true\" #87 pages of true\n",
    "mostly_true = \"mostly-true\" #115 pages\n",
    "half_true = \"half-true\" #125 pages\n",
    "mostly_false = \"barely-true\" #122 pages\n",
    "false = \"false\" #232 pages\n",
    "pants_on_fire = \"pants-fire\" #104 pages\n",
    "truth_values = [true, mostly_true, half_true, mostly_false, false, pants_on_fire]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a85e01bd-4615-4c20-a773-aac9190e917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(url):\n",
    "    r = s.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34871b4f-2772-49d0-8d1b-a8a5f3bf4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArticle(soup):\n",
    "    url_list = []\n",
    "    for i in range(30):\n",
    "        article = soup.find_all('div', {'class': 'm-statement__quote'})[i]\n",
    "        url = 'http://www.politifact.com' + str(article.find('a')['href'])\n",
    "        url_list.append(url)\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "2b7d0279-3bcd-4dee-abf7-51bade9b0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArticleGen(soup):\n",
    "    url_list = []\n",
    "    for i in range(20):\n",
    "        article = soup.find_all('h3', {'class': 'm-teaser__title'})[i]\n",
    "        url = 'http://www.politifact.com' + str(article.find('a')['href'])\n",
    "        url_list.append(url)\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "49f882c0-3dcb-48dd-bd0a-b7675314cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-page genAI data scraping code\n",
    "#used for scraping regular politifact news articles\n",
    "s = HTMLSession()\n",
    "generativeTask_df = pd.DataFrame(columns=['Statement', 'Tldr_text_statements', 'Text'])\n",
    "#total of 389 pages of articles dating back to august 2007\n",
    "for page in range(1, 101):\n",
    "    if page == 1:\n",
    "        url = \"https://www.politifact.com/article/list/\"\n",
    "    else:\n",
    "        url = \"https://www.politifact.com/article/list/?page=\" + str(page)\n",
    "    for i in getArticleGen(getData(url)):\n",
    "        truth_soup = getData(i)\n",
    "    \n",
    "        #statement scrape\n",
    "        statement = truth_soup.find('div', {'class': 'm-statement__quote'}).text.strip()\n",
    "        \n",
    "        #tldr summary text scrape\n",
    "        tldr_text_statements = []\n",
    "        main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "        for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "            if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}):\n",
    "                tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'})\n",
    "                if tldr_text.find_all('p'):\n",
    "                    tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}).find_all('p')\n",
    "                    for i in tldr_text:\n",
    "                        cleaned = i.text.replace('\\xa0', '')\n",
    "                        tldr_text_statements.append(cleaned)\n",
    "                else:\n",
    "                    tldr_text = tldr_text.find_all('li')\n",
    "                    for i in tldr_text:\n",
    "                        cleaned = i.text.replace('\\xa0', '')\n",
    "                        tldr_text_statements.append(cleaned)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        \n",
    "        #full text scrape\n",
    "        text = ''\n",
    "        main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "        for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "            if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}):\n",
    "                full_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}).find_all('p')\n",
    "                for i in full_text:\n",
    "                    text += i.text + ' '\n",
    "                text = text.replace('\\xa0', '')\n",
    "\n",
    "        new_row = {'Statement': statement, 'Tldr_text_statements': tldr_text_statements, 'Text': text}\n",
    "        generativeTask_df.loc[len(generativeTask_df)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779537e-1c07-416c-8fe4-d98da19cd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-page true truth-o-meter scraping code \n",
    "s = HTMLSession()\n",
    "true_df = pd.DataFrame(columns=['Claimer', 'Statement', 'Truth_value', 'Tldr_text_statements', 'Text'])\n",
    "try:\n",
    "    value = \"true\"\n",
    "    for page in range(1, 88):\n",
    "        if page == 1:\n",
    "            url = \"https://www.politifact.com/factchecks/list/?ruling=\" + value\n",
    "        else:\n",
    "            url = \"https://www.politifact.com/factchecks/list/?page=\" + str(page) + \"&ruling=\" + value\n",
    "        for i in getArticle(getData(url)):\n",
    "            truth_soup = getData(i)\n",
    "            #claimer scrape\n",
    "            claimer = truth_soup.find('div', {'class': 'm-statement__meta'}).find('a')['title']\n",
    "\n",
    "            #statement scrape\n",
    "            statement = truth_soup.find('div', {'class': 'm-statement__quote'}).text.strip()\n",
    "\n",
    "            #truth value scrape\n",
    "            truth_value = truth_soup.find('div', {'class': 'm-statement__meter'}).find('div', {'class': 'c-image'}).find('img')['alt']\n",
    "\n",
    "            #tldr summary text scrape\n",
    "            tldr_text_statements = []\n",
    "            main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "            for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "                if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}):\n",
    "                    tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'})\n",
    "                    if tldr_text.find_all('p'):\n",
    "                        tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}).find_all('p')\n",
    "                        for i in tldr_text:\n",
    "                            cleaned = i.text.replace('\\xa0', '')\n",
    "                            tldr_text_statements.append(cleaned)\n",
    "                    else:\n",
    "                        tldr_text = tldr_text.find_all('li')\n",
    "                        for i in tldr_text:\n",
    "                            cleaned = i.text.replace('\\xa0', '')\n",
    "                            tldr_text_statements.append(cleaned)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "            #full text scrape\n",
    "            text = ''\n",
    "            main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "            for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "                if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}):\n",
    "                    full_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}).find_all('p')\n",
    "                    for i in full_text:\n",
    "                        text += i.text + ' '\n",
    "                    text = text.replace('\\xa0', '')\n",
    "\n",
    "            new_row = {'Claimer': claimer, 'Statement': statement, 'Truth_value': truth_value, 'Tldr_text_statements': tldr_text_statements, 'Text': text}\n",
    "            true_df.loc[len(true_df)] = new_row\n",
    "except IndexError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fea60a-50c6-443e-a2d9-e9c23a7595e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-page mostly true truth-o-meter scraping code \n",
    "s = HTMLSession()\n",
    "mostly_true_df = pd.DataFrame(columns=['Claimer', 'Statement', 'Truth_value', 'Tldr_text_statements', 'Text'])\n",
    "try:\n",
    "    value = \"mostly-true\"\n",
    "    for page in range(1, 126):\n",
    "        if page == 1:\n",
    "            url = \"https://www.politifact.com/factchecks/list/?ruling=\" + value\n",
    "        else:\n",
    "            url = \"https://www.politifact.com/factchecks/list/?page=\" + str(page) + \"&ruling=\" + value\n",
    "        for i in getArticle(getData(url)):\n",
    "            truth_soup = getData(i)\n",
    "            #claimer scrape\n",
    "            claimer = truth_soup.find('div', {'class': 'm-statement__meta'}).find('a')['title']\n",
    "\n",
    "            #statement scrape\n",
    "            statement = truth_soup.find('div', {'class': 'm-statement__quote'}).text.strip()\n",
    "\n",
    "            #truth value scrape\n",
    "            truth_value = truth_soup.find('div', {'class': 'm-statement__meter'}).find('div', {'class': 'c-image'}).find('img')['alt']\n",
    "\n",
    "            #tldr summary text scrape\n",
    "            tldr_text_statements = []\n",
    "            main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "            for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "                if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}):\n",
    "                    tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'})\n",
    "                    if tldr_text.find_all('p'):\n",
    "                        tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}).find_all('p')\n",
    "                        for i in tldr_text:\n",
    "                            cleaned = i.text.replace('\\xa0', '')\n",
    "                            tldr_text_statements.append(cleaned)\n",
    "                    else:\n",
    "                        tldr_text = tldr_text.find_all('li')\n",
    "                        for i in tldr_text:\n",
    "                            cleaned = i.text.replace('\\xa0', '')\n",
    "                            tldr_text_statements.append(cleaned)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "            #full text scrape\n",
    "            text = ''\n",
    "            main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "            for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "                if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}):\n",
    "                    full_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}).find_all('p')\n",
    "                    for i in full_text:\n",
    "                        text += i.text + ' '\n",
    "                    text = text.replace('\\xa0', '')\n",
    "\n",
    "            new_row = {'Claimer': claimer, 'Statement': statement, 'Truth_value': truth_value, 'Tldr_text_statements': tldr_text_statements, 'Text': text}\n",
    "            mostly_true_df.loc[len(mostly_true_df)] = new_row\n",
    "except IndexError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eff4e8-f245-4e44-bca9-86e0b9569554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-page barely true truth-o-meter scraping code \n",
    "s = HTMLSession()\n",
    "barely_true_df = pd.DataFrame(columns=['Claimer', 'Statement', 'Truth_value', 'Tldr_text_statements', 'Text'])\n",
    "try:\n",
    "    value = \"barely-true\"\n",
    "    for page in range(1, 116):\n",
    "        if page == 1:\n",
    "            url = \"https://www.politifact.com/factchecks/list/?ruling=\" + value\n",
    "        else:\n",
    "            url = \"https://www.politifact.com/factchecks/list/?page=\" + str(page) + \"&ruling=\" + value\n",
    "        for i in getArticle(getData(url)):\n",
    "            truth_soup = getData(i)\n",
    "            #claimer scrape\n",
    "            claimer = truth_soup.find('div', {'class': 'm-statement__meta'}).find('a')['title']\n",
    "\n",
    "            #statement scrape\n",
    "            statement = truth_soup.find('div', {'class': 'm-statement__quote'}).text.strip()\n",
    "\n",
    "            #truth value scrape\n",
    "            truth_value = truth_soup.find('div', {'class': 'm-statement__meter'}).find('div', {'class': 'c-image'}).find('img')['alt']\n",
    "\n",
    "            #tldr summary text scrape\n",
    "            tldr_text_statements = []\n",
    "            main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "            for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "                if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}):\n",
    "                    tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'})\n",
    "                    if tldr_text.find_all('p'):\n",
    "                        tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}).find_all('p')\n",
    "                        for i in tldr_text:\n",
    "                            cleaned = i.text.replace('\\xa0', '')\n",
    "                            tldr_text_statements.append(cleaned)\n",
    "                    else:\n",
    "                        tldr_text = tldr_text.find_all('li')\n",
    "                        for i in tldr_text:\n",
    "                            cleaned = i.text.replace('\\xa0', '')\n",
    "                            tldr_text_statements.append(cleaned)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "            #full text scrape\n",
    "            text = ''\n",
    "            main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "            for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "                if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}):\n",
    "                    full_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}).find_all('p')\n",
    "                    for i in full_text:\n",
    "                        text += i.text + ' '\n",
    "                    text = text.replace('\\xa0', '')\n",
    "\n",
    "            new_row = {'Claimer': claimer, 'Statement': statement, 'Truth_value': truth_value, 'Tldr_text_statements': tldr_text_statements, 'Text': text}\n",
    "            barely_true_df.loc[len(barely_true_df)] = new_row\n",
    "except IndexError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e2a639-40a5-4bc5-b6b5-da8f6a18894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-page mostly false truth-o-meter scraping code \n",
    "s = HTMLSession()\n",
    "mostly_false_df = pd.DataFrame(columns=['Claimer', 'Statement', 'Truth_value', 'Tldr_text_statements', 'Text'])\n",
    "try:\n",
    "    value = \"barely-true\"\n",
    "    for page in range(1, 123):\n",
    "        if page == 1:\n",
    "            url = \"https://www.politifact.com/factchecks/list/?ruling=\" + value\n",
    "        else:\n",
    "            url = \"https://www.politifact.com/factchecks/list/?page=\" + str(page) + \"&ruling=\" + value\n",
    "        for i in getArticle(getData(url)):\n",
    "            truth_soup = getData(i)\n",
    "            #claimer scrape\n",
    "            claimer = truth_soup.find('div', {'class': 'm-statement__meta'}).find('a')['title']\n",
    "\n",
    "            #statement scrape\n",
    "            statement = truth_soup.find('div', {'class': 'm-statement__quote'}).text.strip()\n",
    "\n",
    "            #truth value scrape\n",
    "            truth_value = truth_soup.find('div', {'class': 'm-statement__meter'}).find('div', {'class': 'c-image'}).find('img')['alt']\n",
    "\n",
    "            #tldr summary text scrape\n",
    "            tldr_text_statements = []\n",
    "            main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "            for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "                if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}):\n",
    "                    tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'})\n",
    "                    if tldr_text.find_all('p'):\n",
    "                        tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}).find_all('p')\n",
    "                        for i in tldr_text:\n",
    "                            cleaned = i.text.replace('\\xa0', '')\n",
    "                            tldr_text_statements.append(cleaned)\n",
    "                    else:\n",
    "                        tldr_text = tldr_text.find_all('li')\n",
    "                        for i in tldr_text:\n",
    "                            cleaned = i.text.replace('\\xa0', '')\n",
    "                            tldr_text_statements.append(cleaned)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "            #full text scrape\n",
    "            text = ''\n",
    "            main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "            for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "                if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}):\n",
    "                    full_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}).find_all('p')\n",
    "                    for i in full_text:\n",
    "                        text += i.text + ' '\n",
    "                    text = text.replace('\\xa0', '')\n",
    "\n",
    "            new_row = {'Claimer': claimer, 'Statement': statement, 'Truth_value': truth_value, 'Tldr_text_statements': tldr_text_statements, 'Text': text}\n",
    "            mostly_false_df.loc[len(mostly_false_df)] = new_row\n",
    "except IndexError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a45038-a801-4801-950e-0c8bb7bca324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-page false truth-o-meter scraping code \n",
    "s = HTMLSession()\n",
    "false_df = pd.DataFrame(columns=['Claimer', 'Statement', 'Truth_value', 'Tldr_text_statements', 'Text'])\n",
    "try:\n",
    "    value = \"false\"\n",
    "    for page in range(1, 233):\n",
    "        if page == 1:\n",
    "            url = \"https://www.politifact.com/factchecks/list/?ruling=\" + value\n",
    "        else:\n",
    "            url = \"https://www.politifact.com/factchecks/list/?page=\" + str(page) + \"&ruling=\" + value\n",
    "        for i in getArticle(getData(url)):\n",
    "            truth_soup = getData(i)\n",
    "            #claimer scrape\n",
    "            claimer = truth_soup.find('div', {'class': 'm-statement__meta'}).find('a')['title']\n",
    "\n",
    "            #statement scrape\n",
    "            statement = truth_soup.find('div', {'class': 'm-statement__quote'}).text.strip()\n",
    "\n",
    "            #truth value scrape\n",
    "            truth_value = truth_soup.find('div', {'class': 'm-statement__meter'}).find('div', {'class': 'c-image'}).find('img')['alt']\n",
    "\n",
    "            #tldr summary text scrape\n",
    "            tldr_text_statements = []\n",
    "            main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "            for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "                if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}):\n",
    "                    tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'})\n",
    "                    if tldr_text.find_all('p'):\n",
    "                        tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}).find_all('p')\n",
    "                        for i in tldr_text:\n",
    "                            cleaned = i.text.replace('\\xa0', '')\n",
    "                            tldr_text_statements.append(cleaned)\n",
    "                    else:\n",
    "                        tldr_text = tldr_text.find_all('li')\n",
    "                        for i in tldr_text:\n",
    "                            cleaned = i.text.replace('\\xa0', '')\n",
    "                            tldr_text_statements.append(cleaned)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "            #full text scrape\n",
    "            text = ''\n",
    "            main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "            for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "                if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}):\n",
    "                    full_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}).find_all('p')\n",
    "                    for i in full_text:\n",
    "                        text += i.text + ' '\n",
    "                    text = text.replace('\\xa0', '')\n",
    "\n",
    "            new_row = {'Claimer': claimer, 'Statement': statement, 'Truth_value': truth_value, 'Tldr_text_statements': tldr_text_statements, 'Text': text}\n",
    "            false_df.loc[len(false_df)] = new_row\n",
    "except (AttributeError, IndexError) as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1a91043-1eb9-4b7e-baa9-85e6594b2d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-page pants on fire truth-o-meter scraping code \n",
    "s = HTMLSession()\n",
    "pants_fire_df = pd.DataFrame(columns=['Claimer', 'Statement', 'Truth_value', 'Tldr_text_statements', 'Text'])\n",
    "try:\n",
    "    value = \"pants-fire\"\n",
    "    for page in range(1, 105):\n",
    "        if page == 1:\n",
    "            url = \"https://www.politifact.com/factchecks/list/?ruling=\" + value\n",
    "        else:\n",
    "            url = \"https://www.politifact.com/factchecks/list/?page=\" + str(page) + \"&ruling=\" + value\n",
    "        for i in getArticle(getData(url)):\n",
    "            truth_soup = getData(i)\n",
    "            #claimer scrape\n",
    "            claimer = truth_soup.find('div', {'class': 'm-statement__meta'}).find('a')['title']\n",
    "\n",
    "            #statement scrape\n",
    "            statement = truth_soup.find('div', {'class': 'm-statement__quote'}).text.strip()\n",
    "\n",
    "            #truth value scrape\n",
    "            truth_value = truth_soup.find('div', {'class': 'm-statement__meter'}).find('div', {'class': 'c-image'}).find('img')['alt']\n",
    "\n",
    "            #tldr summary text scrape\n",
    "            tldr_text_statements = []\n",
    "            main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "            for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "                if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}):\n",
    "                    tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'})\n",
    "                    if tldr_text.find_all('p'):\n",
    "                        tldr_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('div', {'class': 'short-on-time'}).find_all('p')\n",
    "                        for i in tldr_text:\n",
    "                            cleaned = i.text.replace('\\xa0', '')\n",
    "                            tldr_text_statements.append(cleaned)\n",
    "                    else:\n",
    "                        tldr_text = tldr_text.find_all('li')\n",
    "                        for i in tldr_text:\n",
    "                            cleaned = i.text.replace('\\xa0', '')\n",
    "                            tldr_text_statements.append(cleaned)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "            #full text scrape\n",
    "            text = ''\n",
    "            main_content = truth_soup.find('div', {'class': 'global-wrapper'}).find('main', {'class': 'global-content'})\n",
    "            for i in range(len(main_content.find_all('section', {'class': 't-row'}))):\n",
    "                if main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}):\n",
    "                    full_text = main_content.find_all('section', {'class': 't-row'})[i].find('div', {'class': 't-row__center'}).find('article', {'class': 'm-textblock'}).find_all('p')\n",
    "                    for i in full_text:\n",
    "                        text += i.text + ' '\n",
    "                    text = text.replace('\\xa0', '')\n",
    "\n",
    "            new_row = {'Claimer': claimer, 'Statement': statement, 'Truth_value': truth_value, 'Tldr_text_statements': tldr_text_statements, 'Text': text}\n",
    "            pants_fire_df.loc[len(pants_fire_df)] = new_row\n",
    "except IndexError as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5502d81-1593-4226-be69-0f9a600630b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claimer</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Truth_value</th>\n",
       "      <th>Tldr_text_statements</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>“Every President we ever had in the United Sta...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[Claims that politicians are reptilian are par...</td>\n",
       "      <td>Politicians can seem cold-blooded sometimes. B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Viral image</td>\n",
       "      <td>Video shows a President Joe Biden impostor.</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[Claims that video footage shows a President J...</td>\n",
       "      <td>A recent video revives the conspiracy theory t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>Este video muestra al Dr. Juan Rivera hablando...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[El video del Dr. Juan Rivera no es legítimo.,...</td>\n",
       "      <td>Los médicos y profesionales que aparecen en lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andy Biggs</td>\n",
       "      <td>The Democrats are pushing “to take in a millio...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[The Democratic comments about refugees so far...</td>\n",
       "      <td>Israeli Defense Forces told people in north Ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Instagram posts</td>\n",
       "      <td>“There isn't a single video or photo suggestin...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[The Oct. 7 Hamas attack at the Tribe of Nova ...</td>\n",
       "      <td>Editor’s note: This story contains references ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>Bloggers</td>\n",
       "      <td>Obama says America is great, but let's \"try to...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[]</td>\n",
       "      <td>They have online names like fiberguy, dittohea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>Obama \"basically threatened to bomb Pakistan.\"</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[]</td>\n",
       "      <td>At the Democratic debate in Cleveland, Ohio, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>Bloggers</td>\n",
       "      <td>\"Barack Obama loves Che Guevara.\"</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\nBarack Obama has been subjected to chain e-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>John McCain</td>\n",
       "      <td>Obama \"suggested bombing Pakistan.\"</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[]</td>\n",
       "      <td>At a media availability in Columbus, Ohio, on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>Republican National Committee</td>\n",
       "      <td>RNC version of a Hillary Clinton valentine: \"R...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[]</td>\n",
       "      <td>Its presidential nominee all but announced, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3090 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Claimer  \\\n",
       "0                    Facebook posts   \n",
       "1                       Viral image   \n",
       "2                    Facebook posts   \n",
       "3                        Andy Biggs   \n",
       "4                   Instagram posts   \n",
       "...                             ...   \n",
       "3085                       Bloggers   \n",
       "3086                Hillary Clinton   \n",
       "3087                       Bloggers   \n",
       "3088                    John McCain   \n",
       "3089  Republican National Committee   \n",
       "\n",
       "                                              Statement Truth_value  \\\n",
       "0     “Every President we ever had in the United Sta...  pants-fire   \n",
       "1           Video shows a President Joe Biden impostor.  pants-fire   \n",
       "2     Este video muestra al Dr. Juan Rivera hablando...  pants-fire   \n",
       "3     The Democrats are pushing “to take in a millio...  pants-fire   \n",
       "4     “There isn't a single video or photo suggestin...  pants-fire   \n",
       "...                                                 ...         ...   \n",
       "3085  Obama says America is great, but let's \"try to...  pants-fire   \n",
       "3086     Obama \"basically threatened to bomb Pakistan.\"  pants-fire   \n",
       "3087                  \"Barack Obama loves Che Guevara.\"  pants-fire   \n",
       "3088                Obama \"suggested bombing Pakistan.\"  pants-fire   \n",
       "3089  RNC version of a Hillary Clinton valentine: \"R...  pants-fire   \n",
       "\n",
       "                                   Tldr_text_statements  \\\n",
       "0     [Claims that politicians are reptilian are par...   \n",
       "1     [Claims that video footage shows a President J...   \n",
       "2     [El video del Dr. Juan Rivera no es legítimo.,...   \n",
       "3     [The Democratic comments about refugees so far...   \n",
       "4     [The Oct. 7 Hamas attack at the Tribe of Nova ...   \n",
       "...                                                 ...   \n",
       "3085                                                 []   \n",
       "3086                                                 []   \n",
       "3087                                                 []   \n",
       "3088                                                 []   \n",
       "3089                                                 []   \n",
       "\n",
       "                                                   Text  \n",
       "0     Politicians can seem cold-blooded sometimes. B...  \n",
       "1     A recent video revives the conspiracy theory t...  \n",
       "2     Los médicos y profesionales que aparecen en lo...  \n",
       "3     Israeli Defense Forces told people in north Ga...  \n",
       "4     Editor’s note: This story contains references ...  \n",
       "...                                                 ...  \n",
       "3085  They have online names like fiberguy, dittohea...  \n",
       "3086  At the Democratic debate in Cleveland, Ohio, o...  \n",
       "3087  \\nBarack Obama has been subjected to chain e-m...  \n",
       "3088  At a media availability in Columbus, Ohio, on ...  \n",
       "3089  Its presidential nominee all but announced, th...  \n",
       "\n",
       "[3090 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pants_fire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a8a0a0-c10b-460a-a205-c21659118086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only english news entries from data scrape\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        return 'English' if lang == 'en' else 'Spanish'\n",
    "    except:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5949fa6f-b27c-4dbb-9be3-f0ea8d9446cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claimer</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Truth_value</th>\n",
       "      <th>Tldr_text_statements</th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>“Every President we ever had in the United Sta...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[Claims that politicians are reptilian are par...</td>\n",
       "      <td>Politicians can seem cold-blooded sometimes. B...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Viral image</td>\n",
       "      <td>Video shows a President Joe Biden impostor.</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[Claims that video footage shows a President J...</td>\n",
       "      <td>A recent video revives the conspiracy theory t...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andy Biggs</td>\n",
       "      <td>The Democrats are pushing “to take in a millio...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[The Democratic comments about refugees so far...</td>\n",
       "      <td>Israeli Defense Forces told people in north Ga...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Instagram posts</td>\n",
       "      <td>“There isn't a single video or photo suggestin...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[The Oct. 7 Hamas attack at the Tribe of Nova ...</td>\n",
       "      <td>Editor’s note: This story contains references ...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Instagram posts</td>\n",
       "      <td>Less than 48 hours after Israel was attacked “...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[Russia’s invasion of Ukraine has been well do...</td>\n",
       "      <td>As Russia’s war in Ukraine raged on, a differe...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>Bill Clinton</td>\n",
       "      <td>\"Hillary (Clinton), one time late at night whe...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\n(Published April 11, 2008)\\n \\nBill Clinton ...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>Chain email</td>\n",
       "      <td>\"According to The Book of Revelations the anti...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\nThe chain e-mail attacks on Sen. Barack Obam...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>Bloggers</td>\n",
       "      <td>Obama says America is great, but let's \"try to...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[]</td>\n",
       "      <td>They have online names like fiberguy, dittohea...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>Obama \"basically threatened to bomb Pakistan.\"</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[]</td>\n",
       "      <td>At the Democratic debate in Cleveland, Ohio, o...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>Republican National Committee</td>\n",
       "      <td>RNC version of a Hillary Clinton valentine: \"R...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>[]</td>\n",
       "      <td>Its presidential nominee all but announced, th...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3037 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Claimer  \\\n",
       "0                    Facebook posts   \n",
       "1                       Viral image   \n",
       "3                        Andy Biggs   \n",
       "4                   Instagram posts   \n",
       "5                   Instagram posts   \n",
       "...                             ...   \n",
       "3082                   Bill Clinton   \n",
       "3083                    Chain email   \n",
       "3085                       Bloggers   \n",
       "3086                Hillary Clinton   \n",
       "3089  Republican National Committee   \n",
       "\n",
       "                                              Statement Truth_value  \\\n",
       "0     “Every President we ever had in the United Sta...  pants-fire   \n",
       "1           Video shows a President Joe Biden impostor.  pants-fire   \n",
       "3     The Democrats are pushing “to take in a millio...  pants-fire   \n",
       "4     “There isn't a single video or photo suggestin...  pants-fire   \n",
       "5     Less than 48 hours after Israel was attacked “...  pants-fire   \n",
       "...                                                 ...         ...   \n",
       "3082  \"Hillary (Clinton), one time late at night whe...  pants-fire   \n",
       "3083  \"According to The Book of Revelations the anti...  pants-fire   \n",
       "3085  Obama says America is great, but let's \"try to...  pants-fire   \n",
       "3086     Obama \"basically threatened to bomb Pakistan.\"  pants-fire   \n",
       "3089  RNC version of a Hillary Clinton valentine: \"R...  pants-fire   \n",
       "\n",
       "                                   Tldr_text_statements  \\\n",
       "0     [Claims that politicians are reptilian are par...   \n",
       "1     [Claims that video footage shows a President J...   \n",
       "3     [The Democratic comments about refugees so far...   \n",
       "4     [The Oct. 7 Hamas attack at the Tribe of Nova ...   \n",
       "5     [Russia’s invasion of Ukraine has been well do...   \n",
       "...                                                 ...   \n",
       "3082                                                 []   \n",
       "3083                                                 []   \n",
       "3085                                                 []   \n",
       "3086                                                 []   \n",
       "3089                                                 []   \n",
       "\n",
       "                                                   Text language  \n",
       "0     Politicians can seem cold-blooded sometimes. B...  English  \n",
       "1     A recent video revives the conspiracy theory t...  English  \n",
       "3     Israeli Defense Forces told people in north Ga...  English  \n",
       "4     Editor’s note: This story contains references ...  English  \n",
       "5     As Russia’s war in Ukraine raged on, a differe...  English  \n",
       "...                                                 ...      ...  \n",
       "3082  \\n(Published April 11, 2008)\\n \\nBill Clinton ...  English  \n",
       "3083  \\nThe chain e-mail attacks on Sen. Barack Obam...  English  \n",
       "3085  They have online names like fiberguy, dittohea...  English  \n",
       "3086  At the Democratic debate in Cleveland, Ohio, o...  English  \n",
       "3089  Its presidential nominee all but announced, th...  English  \n",
       "\n",
       "[3037 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pants_fire_df['language'] = pants_fire_df['Statement'].apply(detect_language)\n",
    "english_df = pants_fire_df[pants_fire_df['language'] == 'English']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
